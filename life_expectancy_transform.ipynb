{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Oct  8 11:27:31 2018\n",
    "\n",
    "@author: robertgrant\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "from databaker.framework import *\n",
    "import pandas as pd\n",
    "from databakerUtils.writers import v4Writer\n",
    "import re, requests, json\n",
    "\n",
    "inputfile1 = 'data201315.xls'\n",
    "inputfile2 = 'data201416.xls'\n",
    "inputfile3 = 'data201517.xlsx'\n",
    "outputfile ='v4_le.csv'\n",
    "\n",
    "#these names may change\n",
    "tabsWeWant1 = ['HE at birth - Males', 'HE at birth - Females', 'HE at age 65 - Males', 'HE at age 65 - Females']\n",
    "tabs1 = loadxlstabs(inputfile1, tabsWeWant1)\n",
    "\n",
    "tabsWeWant2 = ['HE - male at birth', 'HE - female at birth', 'HE - male at 65', 'HE - females at 65']\n",
    "tabs2 = loadxlstabs(inputfile2, tabsWeWant2)\n",
    "\n",
    "tabsWeWant3 = ['HE - Male at birth', 'HE - Female at birth', 'HE - Male at age 65', 'HE - Female at age 65']\n",
    "tabs3 = loadxlstabs(inputfile3, tabsWeWant3)\n",
    "\n",
    "tabs = tabs1 + tabs2 + tabs3\n",
    "\n",
    "conversionsegments = []\n",
    "\n",
    "# for each of the selected tabs....do everything thats indented (in this case we only have 1 tab, but that isn't common so we'll stick with the typical approach)\n",
    "for tab in tabs:       \n",
    "\n",
    "    # define a selection of cells as the observations\n",
    "    le = tab.excel_ref('E6').expand(DOWN)\n",
    "    hle = tab.excel_ref('I6').expand(DOWN)\n",
    "    dfle = tab.excel_ref('N6').expand(DOWN)\n",
    "    \n",
    "    \n",
    "    #define which tab this is\n",
    "    thisTab = tab.excel_ref('A1')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    area_codes = tab.excel_ref('A6').expand(DOWN).is_not_blank().is_not_whitespace()\n",
    "    footnotes = tab.excel_ref('A').filter(contains_string('Footnotes')).expand(DOWN)\n",
    "    la_1 = tab.excel_ref('B6').expand(DOWN).is_not_blank().is_not_whitespace()\n",
    "    la_2 = tab.excel_ref('C6').expand(DOWN).is_not_blank().is_not_whitespace()\n",
    "    la_3 = tab.excel_ref('D6').expand(DOWN).is_not_blank().is_not_whitespace()\n",
    "    le_lcl = tab.excel_ref('F6').expand(DOWN).is_not_blank().is_not_whitespace()\n",
    "    hle_lcl = tab.excel_ref('J6').expand(DOWN).is_not_blank().is_not_whitespace()\n",
    "    dfle_lcl = tab.excel_ref('O6').expand(DOWN).is_not_blank().is_not_whitespace()\n",
    "    le_ucl = tab.excel_ref('G6').expand(DOWN).is_not_blank().is_not_whitespace()\n",
    "    hle_ucl = tab.excel_ref('K6').expand(DOWN).is_not_blank().is_not_whitespace()\n",
    "    dfle_ucl = tab.excel_ref('P6').expand(DOWN).is_not_blank().is_not_whitespace()\n",
    "    la_full = la_1 | la_2 | la_3\n",
    "    lcl = le_lcl | hle_lcl | dfle_lcl\n",
    "    ucl = le_ucl | hle_ucl | dfle_ucl\n",
    "    area_codes = area_codes - footnotes\n",
    "\n",
    "   \n",
    "    \n",
    "    names = tab.excel_ref('E4').expand(RIGHT)\n",
    "  \n",
    "    \n",
    "    \n",
    "    dimensions = [\n",
    "              HDim(area_codes, \"mid-year-pop-geography\", DIRECTLY, LEFT),\n",
    "              HDim(names, \"lifeexpectancyvariable\", DIRECTLY, ABOVE),\n",
    "              HDim(la_full, \"GEOG\", DIRECTLY, LEFT),\n",
    "              HDim(lcl, \"lower-confidence-limit\", DIRECTLY, RIGHT),\n",
    "              HDim(ucl, \"upper-confidence-limit\", DIRECTLY, RIGHT),\n",
    "              HDim(thisTab, \"tab\", CLOSEST, ABOVE)\n",
    "                 ]\n",
    "    \n",
    "    obs = le | hle | dfle\n",
    "    \n",
    "    conversionsegment = ConversionSegment(tab, dimensions, obs).topandas()# < --- processing\n",
    "    conversionsegments.append(conversionsegment) # <-- adding result of processing this tab to our list\n",
    "    \n",
    "# print it all to csv (this code never changes)\n",
    "conversionsegments = pd.concat(conversionsegments)\n",
    "\n",
    "#remove nulls\n",
    "conversionsegments = conversionsegments.dropna(subset=['labels'])\n",
    "\n",
    "#reset index\n",
    "conversionsegments = conversionsegments.reset_index(drop = True)\n",
    "\n",
    "\n",
    "#add data markings\n",
    "for i in range(0, len(conversionsegments)):\n",
    "    if(conversionsegments['OBS'][i] == \"\" and conversionsegments['DATAMARKER'][i] != \"..\"):\n",
    "        conversionsegments['DATAMARKER'][i] = \".\"\n",
    "        conversionsegments['lower-confidence-limit'][i] = \".\"\n",
    "        conversionsegments['upper-confidence-limit'][i] = \".\"\n",
    "\n",
    "#take year\n",
    "conversionsegments['time'] = ''\n",
    "conversionsegments['time'] = conversionsegments['tab'].apply(lambda x: x[-9:])\n",
    "conversionsegments['time'] = conversionsegments['time'].apply(lambda x: x[0:5] + x[7:9])\n",
    "conversionsegments[TIME] = conversionsegments['time']\n",
    "\n",
    "#variables\n",
    "\n",
    "conversionsegments['lifeexpectancyvariable'] = conversionsegments['lifeexpectancyvariable'].replace(\"HLE\",\"Healthy life expectancy\")\n",
    "conversionsegments['lifeexpectancyvariable'] = conversionsegments['lifeexpectancyvariable'].replace(\"DfLE\",\"Disability-free life expectancy\")\n",
    "conversionsegments['lifeexpectancyvariable'] = conversionsegments['lifeexpectancyvariable'].replace(\"LE\",\"Life expectancy\")\n",
    "\n",
    "conversionsegments['life-expectancy-variable'] = conversionsegments['lifeexpectancyvariable'].replace(\"Healthy life expectancy\",\"healthy-life-expectancy\")\n",
    "conversionsegments['life-expectancy-variable'] = conversionsegments['life-expectancy-variable'].replace(\"Disability-free life expectancy\",\"disability-free-life-expectancy\")\n",
    "conversionsegments['life-expectancy-variable'] = conversionsegments['life-expectancy-variable'].replace(\"Life expectancy\",\"life-expectancy\")\n",
    "\n",
    "\n",
    "#check for any blank data\n",
    "check = pd.crosstab(conversionsegments.GEOG ,conversionsegments.lifeexpectancyvariable)\n",
    "check['total'] = check['Life expectancy'] +  check['Healthy life expectancy'] + check['Disability-free life expectancy'] \n",
    "        \n",
    "\n",
    "for i in range(0, len(check)):\n",
    "    if check['total'][i] != 36:\n",
    "        raise ValueError(\"Something may wrong in the data.\\nCheck the 'check' dataframe.\")\n",
    "    \n",
    "\n",
    "#clean up tab\n",
    "\n",
    "#reset index\n",
    "conversionsegments = conversionsegments.reset_index(drop = True)\n",
    "\n",
    "\n",
    "#work out cohort, using regex for rogue capital letters\n",
    "conversionsegments['birthcohort'] = ''\n",
    "conversionsegments['birth-cohort'] = ''\n",
    "\n",
    "for i in range(0, len(conversionsegments)):\n",
    "    if re.search(r' [Mm]ale', conversionsegments['tab'][i]) and re.search('birth', conversionsegments['tab'][i]):\n",
    "        conversionsegments['birth-cohort'][i] = 'birth-males'\n",
    "        conversionsegments['birthcohort'][i] = 'Males at birth'\n",
    "    elif re.search(r'[Ff]emale', conversionsegments['tab'][i]) and re.search('birth', conversionsegments['tab'][i]):\n",
    "        conversionsegments['birth-cohort'][i] = 'birth-females'\n",
    "        conversionsegments['birthcohort'][i] = 'Females at birth'\n",
    "    elif re.search(r' [Mm]ale', conversionsegments['tab'][i]) and re.search('65', conversionsegments['tab'][i]):\n",
    "        conversionsegments['birth-cohort'][i] = 'age-65-males'\n",
    "        conversionsegments['birthcohort'][i] = 'Males at age 65'\n",
    "    elif re.search(r'[Ff]emale', conversionsegments['tab'][i]) and re.search('65', conversionsegments['tab'][i]): \n",
    "        conversionsegments['birth-cohort'][i] = 'age-65-females'\n",
    "        conversionsegments['birthcohort'][i] = 'Females at age 65'\n",
    "    else: conversionsegments['birthcohort'][i] = False\n",
    "\n",
    "\n",
    "#remove inner london\n",
    "conversionsegments = conversionsegments[conversionsegments['GEOG'] != 'Inner London']\n",
    "conversionsegments = conversionsegments[conversionsegments['GEOG'] != 'Outer London']\n",
    "\n",
    "#check against codelist\n",
    "\n",
    "codelist = \"https://api.beta.ons.gov.uk/v1/code-lists/admin-geography/editions/one-off/codes\"            \n",
    "response = requests.get(codelist)\n",
    "codelist_json = response.json()\n",
    "\n",
    "#get all ids\n",
    "codes = list()\n",
    "count = codelist_json['count']\n",
    "\n",
    "codes = list()\n",
    "for i in range(0, count):\n",
    "    codes.append(codelist_json[\"items\"][i]['id'])\n",
    "    \n",
    "labels = list()\n",
    "for i in range(0, count):\n",
    "    labels.append(codelist_json[\"items\"][i]['label'])    \n",
    "   \n",
    "admin_geog = {'codes': codes, 'labels': labels}\n",
    "admin_geog = pd.DataFrame(data = admin_geog)\n",
    "\n",
    "#get codelist from df\n",
    "conversionsegments = conversionsegments.merge(admin_geog, how ='left', left_on='mid-year-pop-geography', right_on='codes')\n",
    "\n",
    "#v4\n",
    "v4 = conversionsegments[['OBS', 'lower-confidence-limit', 'upper-confidence-limit', 'DATAMARKER', 'time', TIME, 'codes', 'labels', 'life-expectancy-variable', 'lifeexpectancyvariable', 'birth-cohort', 'birthcohort']]\n",
    "v4.columns = ['V4_3', 'lower-confidence-limit', 'upper-confidence-limit', 'Data_Marking', 'two-year-intervals', 'time', 'admin-geography', 'geography', 'life-expectancy-variable', 'lifeexpectancyvariable', 'birth-cohort', 'birthcohort']\n",
    "\n",
    "v4.to_csv(outputfile, index = False) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
